{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>cleaned_event</th>\n",
       "      <th>full_text</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Surprise(%)</th>\n",
       "      <th>Reported EPS</th>\n",
       "      <th>Consensus EPS</th>\n",
       "      <th>hr</th>\n",
       "      <th>...</th>\n",
       "      <th>price_change_7</th>\n",
       "      <th>price_change_30</th>\n",
       "      <th>price_change_90</th>\n",
       "      <th>price_change_365</th>\n",
       "      <th>targe_price_change</th>\n",
       "      <th>prev_vix_values</th>\n",
       "      <th>dataset</th>\n",
       "      <th>target</th>\n",
       "      <th>unigram_vec</th>\n",
       "      <th>phrase_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-07-20</td>\n",
       "      <td>143800</td>\n",
       "      <td>EVENTS:\\t\\tFinancial statements and exhibits\\n</td>\n",
       "      <td>[financial statements and exhibits]</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20040720143800...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.01</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.414034</td>\n",
       "      <td>14.17</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-19</td>\n",
       "      <td>174320</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20041019174320...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.58</td>\n",
       "      <td>14.93</td>\n",
       "      <td>-1.208981</td>\n",
       "      <td>15.13</td>\n",
       "      <td>train</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-18</td>\n",
       "      <td>123338</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20050118123338...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>5.15</td>\n",
       "      <td>13.60</td>\n",
       "      <td>-0.250990</td>\n",
       "      <td>12.47</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>140932</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20050413140932...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>14.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-2.19</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.070178</td>\n",
       "      <td>13.31</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-07-19</td>\n",
       "      <td>132220</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20050719132220...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>13.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>11.54</td>\n",
       "      <td>17.17</td>\n",
       "      <td>0.604141</td>\n",
       "      <td>10.45</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    time                                         event_type  \\\n",
       "0  2004-07-20  143800     EVENTS:\\t\\tFinancial statements and exhibits\\n   \n",
       "1  2004-10-19  174320  EVENTS:\\tResults of Operations and Financial C...   \n",
       "2  2005-01-18  123338  EVENTS:\\tResults of Operations and Financial C...   \n",
       "3  2005-04-13  140932  EVENTS:\\tResults of Operations and Financial C...   \n",
       "4  2005-07-19  132220  EVENTS:\\tResults of Operations and Financial C...   \n",
       "\n",
       "                                       cleaned_event  \\\n",
       "0                [financial statements and exhibits]   \n",
       "1  [results of operations and financial condition...   \n",
       "2  [results of operations and financial condition...   \n",
       "3  [results of operations and financial condition...   \n",
       "4  [results of operations and financial condition...   \n",
       "\n",
       "                                           full_text symbol  Surprise(%)  \\\n",
       "0  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20040720143800...   FULT        -3.13   \n",
       "1  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20041019174320...   FULT         0.00   \n",
       "2  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20050118123338...   FULT         0.00   \n",
       "3  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20050413140932...   FULT         0.00   \n",
       "4  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20050719132220...   FULT         0.00   \n",
       "\n",
       "   Reported EPS  Consensus EPS     hr  ...  price_change_7  price_change_30  \\\n",
       "0          0.31           0.32  14.38  ...           -0.50             2.57   \n",
       "1          0.32           0.32  17.43  ...            0.16             0.39   \n",
       "2          0.33           0.33  12.33  ...            0.53             0.61   \n",
       "3          0.33           0.33  14.09  ...           -1.75            -2.19   \n",
       "4          0.27           0.27  13.22  ...           -1.28             2.88   \n",
       "\n",
       "   price_change_90  price_change_365  targe_price_change  prev_vix_values  \\\n",
       "0             3.01              8.21            0.414034            14.17   \n",
       "1             7.58             14.93           -1.208981            15.13   \n",
       "2             5.15             13.60           -0.250990            12.47   \n",
       "3            -1.37              8.56            0.070178            13.31   \n",
       "4            11.54             17.17            0.604141            10.45   \n",
       "\n",
       "   dataset  target                                        unigram_vec  \\\n",
       "0    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    train    DOWN  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          phrase_vec  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('../data/processed/feature_encoded_merged_data.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_test = pd.read_csv('../data/t-test.csv')\n",
    "# t_test = t_test.dropna(subset=['t values'])\n",
    "# t_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prob(t_val):\n",
    "#     return t.sf(abs(t_val), 2998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_test['Probabilities'] = t_test['Coefficients'].apply(get_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrase_indicies = t_test.sort_values(by = ['Probabilities']).head(2319).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def select_phrases(phrases):\n",
    "#     return np.array(phrases)[phrase_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# data['top_phrases'] = data['phrase_vec'].apply(select_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_phrases(phrases):\n",
    "    return phrases[:2107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['top_phrases'] = data['phrase_vec'].apply(select_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits and Events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data['dataset'] == 'train'].copy()\n",
    "val = data.loc[data['dataset'] == 'val'].copy()\n",
    "test = data.loc[data['dataset'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "all_events = pd.DataFrame(mlb.fit_transform(data['cleaned_event']),\n",
    "                   columns = mlb.classes_,\n",
    "                   index = data['cleaned_event'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA by split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>DOWN</th>\n",
       "      <th>STAY</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_data</th>\n",
       "      <td>0.381330</td>\n",
       "      <td>0.216474</td>\n",
       "      <td>0.402195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.372236</td>\n",
       "      <td>0.213762</td>\n",
       "      <td>0.414003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>0.392472</td>\n",
       "      <td>0.215515</td>\n",
       "      <td>0.392013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.388398</td>\n",
       "      <td>0.222859</td>\n",
       "      <td>0.388742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target        DOWN      STAY        UP\n",
       "all_data  0.381330  0.216474  0.402195\n",
       "train     0.372236  0.213762  0.414003\n",
       "val       0.392472  0.215515  0.392013\n",
       "test      0.388398  0.222859  0.388742"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = [data.groupby(data['target']).count()['symbol'] / data.shape[0],\n",
    "                     train.groupby(train['target']).count()['symbol'] / train.shape[0],\n",
    "                     val.groupby(val['target']).count()['symbol'] / val.shape[0],\n",
    "                     test.groupby(test['target']).count()['symbol'] / test.shape[0]],\n",
    "             index = [\"all_data\", \"train\", \"val\", \"test\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>target</th>\n",
       "      <th>DOWN</th>\n",
       "      <th>STAY</th>\n",
       "      <th>UP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_data</th>\n",
       "      <td>-5.416298</td>\n",
       "      <td>-0.032407</td>\n",
       "      <td>5.942713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>-5.692446</td>\n",
       "      <td>-0.038576</td>\n",
       "      <td>6.178306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>-4.850204</td>\n",
       "      <td>-0.033597</td>\n",
       "      <td>5.717755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>-5.458181</td>\n",
       "      <td>-0.019418</td>\n",
       "      <td>5.667296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "target        DOWN      STAY        UP\n",
       "all_data -5.416298 -0.032407  5.942713\n",
       "train    -5.692446 -0.038576  6.178306\n",
       "val      -4.850204 -0.033597  5.717755\n",
       "test     -5.458181 -0.019418  5.667296"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = [data.groupby(data['target']).mean()['targe_price_change'],\n",
    "                     train.groupby(train['target']).mean()['targe_price_change'],\n",
    "                     val.groupby(val['target']).mean()['targe_price_change'],\n",
    "                     test.groupby(test['target']).mean()['targe_price_change']],\n",
    "             index = [\"all_data\", \"train\", \"val\", \"test\"]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_X = train[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_scaler = StandardScaler()\n",
    "uni_scaler.fit(num_train_X)\n",
    "num_train_X = uni_scaler.transform(num_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events = all_events.iloc[train.index].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_y = train[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_X = np.concatenate((train_events, num_train_X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestClassifier(max_depth = 10, n_estimators = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.3 s, sys: 372 ms, total: 34.6 s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "base_model = base_model.fit(base_train_X, base_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/base_model.pckl', 'wb') as f:\n",
    "        pickle.dump(base_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56365303082388"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(base_model.predict(base_train_X) == base_train_y) / len(base_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_X = val[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_X = uni_scaler.transform(num_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_events = all_events.iloc[val.index].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_val_y = val[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_val_X = np.concatenate((val_events, num_val_X), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5105577232040395"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(base_model.predict(base_val_X) == base_val_y) / len(base_val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_prep_uni(train, val):\n",
    "    numerics_train = train[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "    \n",
    "    scale = StandardScaler()\n",
    "    scale.fit(numerics_train)\n",
    "    numerics_train = scale.transform(numerics_train)\n",
    "    \n",
    "    train_unigrams = np.array(train['unigram_vec'].values.tolist())\n",
    "    train_events = all_events.iloc[train.index].to_numpy()\n",
    "    \n",
    "    train_y = train[['target']].to_numpy().ravel()\n",
    "    train_X = np.concatenate((train_events, numerics_train, train_unigrams), axis = 1)\n",
    "    \n",
    "    numerics_val = val[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "    numerics_val = scale.transform(numerics_val)\n",
    "    \n",
    "    val_unigrams = np.array(val['unigram_vec'].values.tolist())\n",
    "    val_events = all_events.iloc[val.index].to_numpy()\n",
    "    \n",
    "    val_y = val[['target']].to_numpy().ravel()\n",
    "    val_X = np.concatenate((val_events, numerics_val, val_unigrams), axis = 1)\n",
    "    \n",
    "    \n",
    "    comb_X = np.concatenate((train_X, val_X), axis = 0)\n",
    "    comb_y = np.concatenate((train_y, val_y), axis = 0)\n",
    "    split_index = np.concatenate((np.ones(train.shape[0]), np.zeros(val.shape[0])), axis = 0)\n",
    "    \n",
    "    return (comb_X, comb_y, split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_X, comb_y, split_index = feature_prep_uni(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [2000]\n",
    "max_depth = [10]\n",
    "max_features = [250, 750, 1500, 'auto']\n",
    "param_grid = dict(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_search = GridSearchCV(uni_model, param_grid, scoring = 'accuracy', cv = pds, refit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "uni_search.fit(comb_X, comb_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_X = train[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "uni_scaler = StandardScaler()\n",
    "uni_scaler.fit(num_train_X)\n",
    "num_train_X = uni_scaler.transform(num_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unigrams = np.array(train['unigram_vec'].values.tolist())\n",
    "train_events = all_events.iloc[train.index].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_train_y = train[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_train_X = np.concatenate((train_events, num_train_X, train_unigrams), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_model_best = RandomForestClassifier(max_depth = 10, n_estimators = 2000, max_features = 1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37min 19s, sys: 5.04 s, total: 37min 24s\n",
      "Wall time: 37min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features=1250,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "uni_model_best.fit(uni_train_X, uni_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6659218517245331"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(uni_model_best.predict(uni_train_X) == uni_train_y) / len(uni_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_X = val[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "num_val_X = uni_scaler.transform(num_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_unigrams = np.array(val['unigram_vec'].values.tolist())\n",
    "val_events = all_events.iloc[val.index].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_val_y = val[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_val_X = np.concatenate((val_events, num_val_X, val_unigrams), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5114757860913473"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(uni_model_best.predict(uni_val_X) == uni_val_y) / len(uni_val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_prep_phrase(train, val):\n",
    "    numerics_train = train[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "    \n",
    "    scale = StandardScaler()\n",
    "    scale.fit(numerics_train)\n",
    "    numerics_train = scale.transform(numerics_train)\n",
    "    \n",
    "    train_unigrams = np.array(train['top_phrases'].values.tolist())\n",
    "    train_events = all_events.iloc[train.index].to_numpy()\n",
    "    \n",
    "    train_y = train[['target']].to_numpy().ravel()\n",
    "    train_X = np.concatenate((train_events, numerics_train, train_unigrams), axis = 1)\n",
    "    \n",
    "    numerics_val = val[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "    numerics_val = scale.transform(numerics_val)\n",
    "    \n",
    "    val_unigrams = np.array(val['top_phrases'].values.tolist())\n",
    "    val_events = all_events.iloc[val.index].to_numpy()\n",
    "    \n",
    "    val_y = val[['target']].to_numpy().ravel()\n",
    "    val_X = np.concatenate((val_events, numerics_val, val_unigrams), axis = 1)\n",
    "    \n",
    "    \n",
    "    comb_X = np.concatenate((train_X, val_X), axis = 0)\n",
    "    comb_y = np.concatenate((train_y, val_y), axis = 0)\n",
    "    split_index = np.concatenate((np.ones(train.shape[0]), np.zeros(val.shape[0])), axis = 0)\n",
    "    \n",
    "    return (comb_X, comb_y, split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_X, comb_y, split_index = feature_prep_phrase(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = PredefinedSplit(test_fold = split_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [2000]\n",
    "max_depth = [10]\n",
    "max_features = [250, 750, 1500, 'auto']\n",
    "param_grid = dict(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_search = GridSearchCV(phrase_model, param_grid, scoring = 'accuracy', cv = pds, refit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "phrase_search.fit(comb_X, comb_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_X = train[['Surprise(%)', 'price_change_7', \n",
    "               'price_change_30', 'price_change_90', 'price_change_365',\n",
    "               'prev_vix_values']].to_numpy()\n",
    "\n",
    "phrase_scaler = StandardScaler()\n",
    "phrase_scaler.fit(num_train_X)\n",
    "num_train_X = phrase_scaler.transform(num_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events = all_events.iloc[train.index].to_numpy()\n",
    "train_phrase = np.array(train['top_phrases'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_train_y = train[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_train_X = np.concatenate((train_events, num_train_X, train_phrase), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_model_best = RandomForestClassifier(max_depth = 10, n_estimators = 1000, max_features = 1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 25s, sys: 4.18 s, total: 18min 29s\n",
      "Wall time: 18min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=10, max_features=1250,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "phrase_model_best.fit(phrase_train_X, phrase_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6234674000229173"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(phrase_model_best.predict(phrase_train_X) == phrase_train_y) / len(phrase_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_X = val[['Surprise(%)', 'price_change_7', \n",
    "               'price_change_30', 'price_change_90', 'price_change_365',\n",
    "               'prev_vix_values']].to_numpy()\n",
    "\n",
    "num_val_X = phrase_scaler.transform(num_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_events = all_events.iloc[val.index].to_numpy()\n",
    "val_phrase = np.array(val['top_phrases'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_val_y = val[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_val_X = np.concatenate((val_events, num_val_X, val_phrase), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5109019967867799"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(phrase_model_best.predict(phrase_val_X) == phrase_val_y) / len(phrase_val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_X = train[['Surprise(%)', 'price_change_7', \n",
    "               'price_change_30', 'price_change_90', 'price_change_365',\n",
    "               'prev_vix_values']].to_numpy()\n",
    "\n",
    "test_scaler = StandardScaler()\n",
    "\n",
    "num_test_X = test[['Surprise(%)', 'price_change_7', \n",
    "               'price_change_30', 'price_change_90', 'price_change_365',\n",
    "               'prev_vix_values']].to_numpy()\n",
    "\n",
    "test_scaler.fit(num_train_X)\n",
    "num_test_X = phrase_scaler.transform(num_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_events = all_events.iloc[test.index].to_numpy()\n",
    "\n",
    "test_unigrams = np.array(test['unigram_vec'].values.tolist())\n",
    "test_phrase = np.array(test['top_phrases'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test_X = np.concatenate((test_events, num_test_X), axis = 1)\n",
    "unigram_test_X = np.concatenate((test_events, num_test_X, test_unigrams), axis = 1)\n",
    "phrase_test_X = np.concatenate((test_events, num_test_X, test_phrase), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[['target']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5194313882838473\n",
      "0.525621919064542\n",
      "0.5261951163590508\n"
     ]
    }
   ],
   "source": [
    "test['base_pred'] = base_model.predict(base_test_X)\n",
    "print(sum(test['base_pred'] == test_y) / len(test_y))\n",
    "\n",
    "test['unigram_pred'] = uni_model_best.predict(unigram_test_X)\n",
    "print(sum(test['unigram_pred'] == test_y) / len(test_y))\n",
    "\n",
    "test['phrase_pred'] = phrase_model_best.predict(phrase_test_X)\n",
    "print(sum(test['phrase_pred'] == test_y) / len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_pickle('../data/model_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_X = train[['Surprise(%)', 'price_change_7', \n",
    "               'price_change_30', 'price_change_90', 'price_change_365',\n",
    "               'prev_vix_values']].to_numpy()\n",
    "\n",
    "phrase_scaler = StandardScaler()\n",
    "phrase_scaler.fit(num_train_X)\n",
    "num_train_X = phrase_scaler.transform(num_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_X = val[['Surprise(%)', 'price_change_7', \n",
    "               'price_change_30', 'price_change_90', 'price_change_365',\n",
    "               'prev_vix_values']].to_numpy()\n",
    "\n",
    "num_data_X = phrase_scaler.transform(num_val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['uni_pred'] = uni_model_best.predict(uni_val_X)\n",
    "uni_val_results = val.loc[val['target'] != val['uni_pred']].copy()\n",
    "uni_val_results = uni_val_results.groupby(val['target']).count()['symbol'] / uni_val_results.shape[0]\n",
    "uni_val_results = uni_val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val['phrase_pred'] = phrase_model_best.predict(phrase_val_X)\n",
    "phrase_val_results = val.loc[val['target'] != val['phrase_pred']].copy()\n",
    "phrase_val_results = phrase_val_results.groupby(val['target']).count()['symbol'] / phrase_val_results.shape[0]\n",
    "phrase_val_results = phrase_val_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DOWN</th>\n",
       "      <td>0.463989</td>\n",
       "      <td>0.475217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAY</th>\n",
       "      <td>0.420013</td>\n",
       "      <td>0.411869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UP</th>\n",
       "      <td>0.115997</td>\n",
       "      <td>0.112914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          symbol    symbol\n",
       "target                    \n",
       "DOWN    0.463989  0.475217\n",
       "STAY    0.420013  0.411869\n",
       "UP      0.115997  0.112914"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([uni_val_results, phrase_val_results], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
