{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>cleaned_event</th>\n",
       "      <th>full_text</th>\n",
       "      <th>symbol</th>\n",
       "      <th>Surprise(%)</th>\n",
       "      <th>Reported EPS</th>\n",
       "      <th>Consensus EPS</th>\n",
       "      <th>hr</th>\n",
       "      <th>...</th>\n",
       "      <th>price_change_7</th>\n",
       "      <th>price_change_30</th>\n",
       "      <th>price_change_90</th>\n",
       "      <th>price_change_365</th>\n",
       "      <th>targe_price_change</th>\n",
       "      <th>prev_vix_values</th>\n",
       "      <th>dataset</th>\n",
       "      <th>target</th>\n",
       "      <th>unigram_vec</th>\n",
       "      <th>phrase_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-07-20</td>\n",
       "      <td>143800</td>\n",
       "      <td>EVENTS:\\t\\tFinancial statements and exhibits\\n</td>\n",
       "      <td>[financial statements and exhibits]</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20040720143800...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>14.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.01</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.414034</td>\n",
       "      <td>14.17</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-19</td>\n",
       "      <td>174320</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20041019174320...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>17.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.58</td>\n",
       "      <td>14.93</td>\n",
       "      <td>-1.208981</td>\n",
       "      <td>15.13</td>\n",
       "      <td>train</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-01-18</td>\n",
       "      <td>123338</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20050118123338...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>12.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>5.15</td>\n",
       "      <td>13.60</td>\n",
       "      <td>-0.250990</td>\n",
       "      <td>12.47</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>140932</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20050413140932...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>14.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-2.19</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.070178</td>\n",
       "      <td>13.31</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-07-19</td>\n",
       "      <td>132220</td>\n",
       "      <td>EVENTS:\\tResults of Operations and Financial C...</td>\n",
       "      <td>[results of operations and financial condition...</td>\n",
       "      <td>\\n&lt;DOCUMENT&gt;\\nFILE:FULT/FULT-8K-20050719132220...</td>\n",
       "      <td>FULT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.27</td>\n",
       "      <td>13.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>2.88</td>\n",
       "      <td>11.54</td>\n",
       "      <td>17.17</td>\n",
       "      <td>0.604141</td>\n",
       "      <td>10.45</td>\n",
       "      <td>train</td>\n",
       "      <td>STAY</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    time                                         event_type  \\\n",
       "0  2004-07-20  143800     EVENTS:\\t\\tFinancial statements and exhibits\\n   \n",
       "1  2004-10-19  174320  EVENTS:\\tResults of Operations and Financial C...   \n",
       "2  2005-01-18  123338  EVENTS:\\tResults of Operations and Financial C...   \n",
       "3  2005-04-13  140932  EVENTS:\\tResults of Operations and Financial C...   \n",
       "4  2005-07-19  132220  EVENTS:\\tResults of Operations and Financial C...   \n",
       "\n",
       "                                       cleaned_event  \\\n",
       "0                [financial statements and exhibits]   \n",
       "1  [results of operations and financial condition...   \n",
       "2  [results of operations and financial condition...   \n",
       "3  [results of operations and financial condition...   \n",
       "4  [results of operations and financial condition...   \n",
       "\n",
       "                                           full_text symbol  Surprise(%)  \\\n",
       "0  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20040720143800...   FULT        -3.13   \n",
       "1  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20041019174320...   FULT         0.00   \n",
       "2  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20050118123338...   FULT         0.00   \n",
       "3  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20050413140932...   FULT         0.00   \n",
       "4  \\n<DOCUMENT>\\nFILE:FULT/FULT-8K-20050719132220...   FULT         0.00   \n",
       "\n",
       "   Reported EPS  Consensus EPS     hr  ...  price_change_7  price_change_30  \\\n",
       "0          0.31           0.32  14.38  ...           -0.50             2.57   \n",
       "1          0.32           0.32  17.43  ...            0.16             0.39   \n",
       "2          0.33           0.33  12.33  ...            0.53             0.61   \n",
       "3          0.33           0.33  14.09  ...           -1.75            -2.19   \n",
       "4          0.27           0.27  13.22  ...           -1.28             2.88   \n",
       "\n",
       "   price_change_90  price_change_365  targe_price_change  prev_vix_values  \\\n",
       "0             3.01              8.21            0.414034            14.17   \n",
       "1             7.58             14.93           -1.208981            15.13   \n",
       "2             5.15             13.60           -0.250990            12.47   \n",
       "3            -1.37              8.56            0.070178            13.31   \n",
       "4            11.54             17.17            0.604141            10.45   \n",
       "\n",
       "   dataset  target                                        unigram_vec  \\\n",
       "0    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    train    DOWN  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4    train    STAY  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          phrase_vec  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('../data/processed/feature_encoded_merged_data.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test = pd.read_csv('../data/t-test.csv')\n",
    "t_test = t_test.dropna(subset=['t values'])\n",
    "t_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(t_val):\n",
    "    return t.sf(abs(t_val), 2998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test['Probabilities'] = t_test['Coefficients'].apply(get_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_indicies = t_test.sort_values(by = ['Probabilities']).head(2319).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_phrases(phrases):\n",
    "    return np.array(phrases)[phrase_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 298 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['top_phrases'] = data['phrase_vec'].apply(select_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits and Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data['dataset'] == 'train'].copy()\n",
    "val = data.loc[data['dataset'] == 'val'].copy()\n",
    "test = data.loc[data['dataset'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "all_events = pd.DataFrame(mlb.fit_transform(data['cleaned_event']),\n",
    "                   columns = mlb.classes_,\n",
    "                   index = data['cleaned_event'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_train = train[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "    \n",
    "scale = StandardScaler()\n",
    "scale.fit(numerics_train)\n",
    "numerics_train = scale.transform(numerics_train)\n",
    "    \n",
    "train_unigrams = np.array(train['unigram_vec'].values.tolist())\n",
    "train_events = all_events.iloc[train.index].to_numpy()\n",
    "    \n",
    "train_y = train[['target']].to_numpy().ravel()\n",
    "train_X = np.concatenate((train_events, numerics_train, train_unigrams), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[100, 10, 1.0, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_model = LogisticRegression(penalty = \"l2\", C = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 1min 38s, total: 2min 40s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "uni_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.545147244184714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(uni_model.predict(train_X) == train_y) / len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_val = val[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "numerics_val = scale.transform(numerics_val)\n",
    "    \n",
    "val_unigrams = np.array(val['unigram_vec'].values.tolist())\n",
    "val_events = all_events.iloc[val.index].to_numpy()\n",
    "    \n",
    "val_y = val[['target']].to_numpy().ravel()\n",
    "val_X = np.concatenate((val_events, numerics_val, val_unigrams), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4091117741565297"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(uni_model.predict(val_X) == val_y) / len(val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_X = train[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "phrase_scaler = StandardScaler()\n",
    "phrase_scaler.fit(num_train_X)\n",
    "num_train_X = phrase_scaler.transform(num_train_X)\n",
    "\n",
    "train_events = all_events.iloc[train.index].to_numpy()\n",
    "train_phrase = np.array(train['top_phrases'].values.tolist())\n",
    "\n",
    "phrase_train_y = train[['target']].to_numpy().ravel()\n",
    "\n",
    "phrase_train_X = np.concatenate((train_events, num_train_X, train_phrase), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_model = LogisticRegression(penalty = \"l2\", C = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1min 56s, total: 3min 1s\n",
      "Wall time: 1min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "phrase_model.fit(phrase_train_X, phrase_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5649707803368855"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(phrase_model.predict(phrase_train_X) == phrase_train_y) / len(phrase_train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val_X = val[['Surprise(%)', 'price_change_7', \n",
    "              'price_change_30', 'price_change_90', 'price_change_365',\n",
    "              'prev_vix_values']].to_numpy()\n",
    "\n",
    "num_val_X = phrase_scaler.transform(num_val_X)\n",
    "\n",
    "val_events = all_events.iloc[val.index].to_numpy()\n",
    "val_phrase = np.array(val['top_phrases'].values.tolist())\n",
    "\n",
    "phrase_val_y = val[['target']].to_numpy().ravel()\n",
    "phrase_val_X = np.concatenate((val_events, num_val_X, val_phrase), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38719302272205647"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(phrase_model.predict(phrase_val_X) == phrase_val_y) / len(phrase_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
